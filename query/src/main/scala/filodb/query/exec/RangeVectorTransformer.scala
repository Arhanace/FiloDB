package filodb.query.exec

import monix.reactive.Observable

import filodb.core.metadata.Column.ColumnType
import filodb.core.metadata.Dataset
import filodb.core.query._
import filodb.query.{AggregationOperator, BinaryOperator, InstantFunctionId, QueryConfig}

/**
  * Implementations can provide ways to transform RangeVector
  * results generated by ExecPlan nodes.
  *
  * Reason why these are not ExecPlan nodes themselves is because
  * they can be applied on the same node where the base RangeVectors
  * are sourced.
  *
  * It can safely be assumed that the operations in these nodes are
  * compute intensive and not I/O intensive.
  */
trait RangeVectorTransformer extends java.io.Serializable {
  def apply(source: Observable[RangeVector],
            queryConfig: QueryConfig,
            limit: Int,
            sourceSchema: ResultSchema): Observable[RangeVector]

  /**
    * Default implementation retains source schema
    */
  def schema(dataset: Dataset, source: ResultSchema): ResultSchema = source

  /**
    * Args to use for the RangeVectorTransformer for printTree purposes only.
    * DO NOT change to a val. Increases heap usage.
    */
  protected[exec] def args: String

}

object RangeVectorTransformer {
  def requireTimeSeries(schema: ResultSchema): Unit = {
    require(schema.isTimeSeries, "Cannot return periodic data from a dataset that is not time series based")
    require(schema.columns.size == 2, "Cannot return periodic data from a dataset that is not time series based")
    require(schema.columns(0).colType == ColumnType.LongColumn,
      "Cannot return periodic data from a dataset that is not time series based")
    require(schema.columns(1).colType == ColumnType.DoubleColumn,
      "Cannot return periodic data from a dataset that is not time series based")
  }
}

/**
  * Applies an instant vector function to every instant/row of the
  * range vectors
  */
final case class InstantVectorFunctionMapper(function: InstantFunctionId,
                                             funcParams: Seq[Any] = Nil) extends RangeVectorTransformer {
  protected[exec] def args: String =
    s"function=$function, funcParams=$funcParams"

  def apply(source: Observable[RangeVector],
            queryConfig: QueryConfig,
            limit: Int,
            sourceSchema: ResultSchema): Observable[RangeVector] = ???

  // TODO all function defs go here and get invoked from mapRangeVector
}

/**
  * Applies a binary operation involving a scalar to every instant/row of the
  * range vectors
  */
final case class ScalarOperationMapper(operator: BinaryOperator,
                                       scalar: AnyVal,
                                       scalarOnLhs: Boolean) extends RangeVectorTransformer {
  protected[exec] def args: String =
    s"operator=$operator, scalar=$scalar"

  def apply(source: Observable[RangeVector],
            queryConfig: QueryConfig,
            limit: Int,
            sourceSchema: ResultSchema): Observable[RangeVector] = ???

  // TODO all operation defs go here and get invoked from mapRangeVector
}

/**
  * Performs aggregation operation across RangeVectors within a shard
  */
final case class AggregateMapReduce(aggrOp: AggregationOperator,
                                    aggrParams: Seq[Any],
                                    without: Seq[String],
                                    by: Seq[String]) extends RangeVectorTransformer {
  require(without == Nil || by == Nil, "Cannot specify both without and by clause")

  protected[exec] def args: String =
    s"aggrOp=$aggrOp, aggrParams=$aggrParams, without=$without, by=$by"
  val aggregator = RowAggregator(aggrOp, aggrParams)

  def apply(source: Observable[RangeVector],
            queryConfig: QueryConfig,
            limit: Int,
            sourceSchema: ResultSchema): Observable[RangeVector] = {
    def grouping(rv: RangeVector): RangeVectorKey = {
      val groupBy = if (by.nonEmpty) rv.key.labelValues.filter(lv => by.contains(lv.label.asNewString))
                    else if (without.nonEmpty) rv.key.labelValues.filterNot(lv =>without.contains(lv.label.asNewString))
                    else Nil
      CustomRangeVectorKey(groupBy)
    }
    RangeVectorAggregator.mapReduce(aggrOp, aggrParams, skipMapPhase = false, source, grouping)
  }

  override def schema(dataset: Dataset, source: ResultSchema): ResultSchema = {
    // TODO we assume that second column needs to be aggregated. Other dataset types need to be accommodated.
    aggregator.reductionSchema(source)
  }
}

final case class AggregatePresenter(aggrOp: AggregationOperator,
                                   aggrParams: Seq[Any]) extends RangeVectorTransformer {

  protected[exec] def args: String = s"aggrOp=$aggrOp, aggrParams=$aggrParams"
  val aggregator = RowAggregator(aggrOp, aggrParams)

  def apply(source: Observable[RangeVector],
            queryConfig: QueryConfig,
            limit: Int,
            sourceSchema: ResultSchema): Observable[RangeVector] = {
    RangeVectorAggregator.present(aggrOp, aggrParams, source, limit)
  }

  override def schema(dataset: Dataset, source: ResultSchema): ResultSchema = {
    aggregator.presentationSchema(source)
  }
}

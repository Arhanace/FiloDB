################################################################
# The FiloDB Kafka config - override in deploy configs
################################################################

filodb {
  kafka {
    # The number of partitions for the filodb ingestion topic
    partitions = 128

    # User must provide their own:
    # record-converter = "filodb.kafka.SimpleRecordConverter"

    # Configure topic for filodb ingestion and failure via config as:
    # `filodb.kafka.topics.ingestion` and
    # `filodb.kafka.topics.failure` for the producers.
    topics {
      # filo_db
      ingestion = "filo_db"
      failure = "failure"
    }

    # Kafka `bootstrap.servers` is common for any producer and consumer.
    # These should be passed in via config as: `filodb.kafka.bootstrap.servers`
    # to be fed into any producer, consumer or streams config.
    bootstrap.servers = [
      "localhost:9092"
    ]

    # streams-specific settings should be passed in via config as:
    # `filodb.kafka.streams` to be fed into any producer config.
    streams {
      # User must provide custom implementation.
      # The converter to use for converting user events to Seq[IngestRecord].
      # of filodb.kafka.RecordConverter
      ingestion = ""
      process.interval.ms = 1000
    }

    failures {
      # Optionally publish failures to subscribers, enabling
      # more immediate response to failures, and capture for
      # cumulative analysis and query later.
      channel-enabled = false
    }

    # Internal FiloDB Kafka tasks
    tasks {
      publish-timeout = 5000ms
      status-timeout = 3000ms
      lifecycle {
        connect-timeout = 8000ms
        shutdown-timeout = 10s
      }
      status {
        log-interval = 5000ms
      }
    }

    # Kafka client security settings are common for any producer and consumer.
    # These should be passed in via config as:
    #   `filodb.kafka.security.*`
    #   `filodb.kafka.sasl.*`
    #   `filodb.kafka.ssl.*`
    # to be fed into any producer, consumer or streams config.
    security.enabled = off
    # SASL/PLAIN is a simple username/password authentication mechanism that
    # is typically used with TLS for encryption to implement secure authentication.
    # Kafka supports `SASL_PLAINTEXT` or `SASL_SSL`. Select `SASL_SSL` for PIE Kafka.
    security.protocol = "PLAINTEXT"
    # Kafka brokers supports client authentication via SASL. Multiple SASL mechanisms
    # can be enabled on the broker simultaneously while each client has to choose one mechanism.
    # The currently supported mechanisms are `GSSAPI` (Kerberos) and `PLAIN`.
    sasl.mechanism = "PLAIN"
    ssl.enabled.protocols = "TLSv1.2,TLSv1.1,TLSv1"
    ssl.truststore.type = "JKS"
    ssl.truststore.location = ${?KAFKA_SSL_TRUSTSTORE_LOCATION}
    ssl.truststore.password = ${?KAFKA_SSL_TRUSTSTORE_PASSWORD}
  }
}

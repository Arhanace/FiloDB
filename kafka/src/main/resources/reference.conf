################################################################
# The FiloDB Kafka config - override in deploy configs
################################################################

filodb {

  kafka {

    bootstrap.servers = [
      "localhost:9092"
    ]

    producer {
      #partitioner = "filodb.kafka.temp.ShardPartitioner"
      key.serializer = "org.apache.kafka.common.serialization.LongSerializer"
      value.serializer = "org.apache.kafka.common.serialization.ByteArraySerializer"
    }

    consumer {
      key.deserializer = "org.apache.kafka.common.serialization.LongDeserializer"
      value.deserializer = "org.apache.kafka.common.serialization.ByteArrayDeserializer"
      partition.assignment.strategy = "org.apache.kafka.clients.consumer.RangeAssignor"
      auto.offset.reset = "earliest"
      enable.auto.commit = false
    }

    streams {
      key.serde = "org.apache.kafka.common.serialization.LongSerde"
      value.serde = "org.apache.kafka.common.serialization.ByteArraySerde"
      # The frequency with which to save the position of the processor.
      # Defaults to 30000
      commit.interval.ms = 30000
      # The size of the TCP receive buffer (SO_RCVBUF) to use when reading data.
      # If the value is -1, the OS default will be used. Defaults to 32768.
      receive.buffer.bytes = 32768
      # The maximum number of records to buffer per partition. Defaults to 1000.
      buffered.records.per.partition = 1000
      process.interval.ms = 1000
    }
  }

  client {
    security.enabled = off
    security.protocol = "PLAINTEXT"
    sasl.mechanism = "PLAIN"
  }

  topics {
    ingestion = "filo_db"
    patterns {
      wire-tap = "tap"
      failure = "failure"
    }
  }

  tasks {
    connect-timeout = 8000ms
    provision-timeout = 5000ms
    route-timeout = 5000ms
    events-per-second-and-partition = 8000
    publish-interval = 1000ms
    log-interval = 1000ms
    publish-timeout = 5000ms
    shutdown-timeout = 10s
  }
}
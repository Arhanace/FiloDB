filodb {
  cassandra {
    hosts = ["localhost"]
    port = 9042
    keyspace = "unittest"
    admin-keyspace = "unittest"
    keyspace-replication-options = "{'class': 'SimpleStrategy', 'replication_factor': '1'}"
    lz4-chunk-compress = false
    sstable-compression = "LZ4Compressor"
    write-parallelism = 4
    partition-list-num-stripes-per-shard = 128
    max-retry-attempts = 5
    retry-interval = 10s
    retry-interval-max-jitter = 10s
    ingestion-consistency-level = "ONE"
  }

  store = "timeseries-null"

  columnstore {
    # Number of cache entries for the table cache
    tablecache-size = 50

    # Maximum number of partitions that can be fetched at once that will still fit in
    # one Spark partition/thread when using IN clause in query.
    # If number of partitions are more than this limit then full table scan is performed.
    inquery-partitions-limit = 12
  }

  spark.dataset-ops-timeout = 15s

  memstore {
    chunks-to-keep = 10
    max-chunks-size = 100
    demand-paged-chunk-retention-period = 10 hours
    shard-memory-mb = 100
    groups-per-shard = 4
    max-num-partitions = 250
    flush-task-parallelism = 1
    chunk-duration = 10 minutes
    max-partitions-to-recover = 100
  }

  ingestion-threads = 8

  tasks {
    # Internal task configs for handling lifecycle management and events
    timeouts {
      default = 30s
      initialization = 60s
      graceful-stop = 30s
    }
  }
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  # loglevel = "DEBUG"
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    warn-about-java-serializer-usage = off
    # Make sure all messages are serialized in tests
    # serialize-messages = on
    # Same thing
    # serialize-creators = on
    debug {
      receive = on
      autoreceive = on
      # lifecycle = on
    }

    serializers {
      filoingest = "filodb.coordinator.client.IngestRowsSerializer"
    }

    serialization-bindings {
      "filodb.coordinator.client.IngestionCommands$IngestRows" = filoingest
    }
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      # Leave out the hostname, it will be automatically determined.
      # The Akka port will be overridden by filodb.spark.* settings
      port = 0
      send-buffer-size = 512000b
      receive-buffer-size = 512000b
      maximum-frame-size = 10 MiB
    }
  }

  cluster {
    roles = [worker]
    # don't use sigar for tests, native lib not in path
    metrics.collector-class = akka.cluster.JmxMetricsCollector
  }
}
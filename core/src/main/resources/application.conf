{
  cassandra {
    hosts = ["localhost"]
    port = 9042
    keyspace = "filodb"
  }

  columnstore {
    # Number of cache entries for the table cache
    tablecache-size = 50

    # Number of ChunkRowMap entries to cache
    segment-cache-size = 1000
  }

  memtable {
    # Uncomment to enable mmap-file based memtable for persistence and easy recovery upon crashes.
    # Defaults to in-memory DB only which is lost upon restarts/crashes, but easier for testing.
    # local-filename = "/tmp/filodb.memtable"

    # Maximum rows per dataset/version before ingestRows throws back a PleaseWait.
    max-rows-per-table = 200000

    # Number of rows in memtable before flushes start being triggered
    flush-trigger-rows = 50000

    # The minimum amount of free memory required to accept new rows into memtable
    min-free-mb = 700
  }

  coordinator {
    # how often the scheduler is run to maintain and kick off flush cycles
    # A maximum of one flush for one dataset is kicked off per scheduler run.  If lots of datasets
    # are being ingested at once, or flush-trigger-rows is set low, then this might need to be more
    # frequent.
    scheduler-interval = 1 s

    # Report scheduler stats?  They are OK for logs but super noisy for, say, Spark Shell.
    # Note that you can always dump out scheduler stats with filodb.spark.FiloSetup.scheduler.stats
    scheduler-reporting = false

    # how often the scheduler reports on its stats.  This is not free, as it has to scan the memTable,
    # so don't make it too frequent.
    scheduler-reporting-interval = 30 s
  }

  # Maximum outstanding flush tasks
  scheduler-max-tasks = 16

  # The maximum number of outstanding reprojection futures (one per segment being flushed) across all
  # datasets.  Each future requires memory (for the binary Filo columnar chunks and other state), so
  # if tight on memory, reduce this number.
  max-reprojection-futures = 32

  # Thread pool size for filodb.core reprojection and I/O tasks.
  core-futures-pool-size = 8
}
